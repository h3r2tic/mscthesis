% Chapter 3

\chapter{ Previous work }
\label{Chapter3}
\lhead{Chapter 3. \emph{ Previous work }}

\section{Über- and micro-shaders}

A popular approach at tackling the shader permutation problem is the \emph{ über-shader }. In this technique, the programmer creates a huge monolithic shader containing all the features a rendered object might need. Subsets of the functionality are then selected either at compile-time via preprocessor-based conditional compilation or at run-time via dynamic branching.

TODO: example

While conceptually simple and easy to implement, the über-shader approach is hard to debug and maintain. A more advanced take at the problem is to keep shader fragments separate and merge them conditionally using run-time logic or conservatively, yet statically generate permutations in the content pipeilne. \citet{Hargreaves04} shows an approach based on runtime shader fragment combining. His implementation relies on a simple extension of the HLSL language in order to define the \emph{imports} and \emph{exports} of a shader fragment. Along with a special \emph{interface block}, a preprocessor is able to combine shader fragments together, linking their inputs and outputs. This effectively hides the complexity from the shader author, making maintainance and debugging easier. Hargreaves praises the robustness of this solution and mentions that it allows the usage of the same shader fragments in various rendering algorithms.

This work builds on shader fragment merging and extends it with automatic parameter type coercion and functional composition. I show how to implement such a scheme in a way that's easy to work with even for non-programmers.

% http://books.google.com/books?id=DgMSb_10l7IC&pg=PA555&lpg=PA555&dq=%22uber+shaders%22&source=bl&ots=-mu34jRtzO&sig=C3KIgqPIb6F8MDsOU0tSevVuN8M&hl=en&ei=zPZpTNGHNoGA4Aam1aHJCQ&sa=X&oi=book_result&ct=result&resnum=4&ved=0CCIQ6AEwAzgK#v=onepage&q=%22uber%20shaders%22&f=false

\section{RenderMan}

When designing a graphics rendering system, it's impossible not to bump into what's currently the industry standard for film rendering - PhotoRealistic RenderMan. Despite being over 20 years old, it continues to thrive as the benchmark for all rendering technology. It has been used in several dozen successful feature film productions and among its awards is the first Oscar even awarded to the developers of a software package \cite{RenderManAwards}. An interesting aspect concerning RenderMan is that the overall structure of its Interface Specification (\emph{RISpec} in short) has survived mostly unchanged since its first publication in 1988.

The rendering algorithm mainly utilized by Pixar's flagship implementation of RenderMan is called \textbf{Reyes} (acronym for \emph{Renders Everything You Ever Saw}).

TODO

It provides an intuitive programming model which we'd like to use in real-time. However, direct application of Renderman's model is still far away.

Use Siggraph 2010 notes to note how poorly current GPUs handle micro-polygons.

\section{Deferred rendering}

The standard \emph{Forward} rasterization algorithm requires that material and light shaders for an objects be merged into a single GPU program. The implications are two-fold:
\begin{enumerate}
\item The lower bound on the number of GPU programs that need to be compiled is $O(m * l)$ (where $m$ stands for the number of materials and $l$ for the number of light shader \emph{combinations}), or \emph{multi-pass} rendering must be used.

As explained in chapter 2 [TODO: ref], the number of shaders created this way would be prohibitively large. A workaround is to restrict the possible light shader combinations. This may be achieved via über-lights \cite{UberLights, UberLightsCg} or just constraining the renderer to a handful of light types. Additionally, a common approach may be to fit a shader for more lights than an object is affected by by zeroing-out the non-existent light intensities. For instance, when the renderer must render an object influenced by two point-lights, it may use a shader for rendering it with three point-lights, assuming zero intensity for one of the shader parameters. Naturally, this approach, just like the über-light one, carries a runtime cost which may be prohibitive for a complex setup.

An alternative approach to this issue is \emph{multi-pass} rendering, where the object is rendered once for an affecting light, and the resulting illumination is summed via additive blending. The downside to this solution is that in scenes with complex geometry, rendering objects multiple times will quickly drain the computational budget.

\item Lights can only influence the scene at the granularity of individual objects, not their vertices or rasterized pixels. Even when a light would affect a small part of an object, it must be evaluated for all elements thereof, because a single \emph{batch} may only use a single shader per domain.

Splitting objects into smaller pieces might be an option, however GPU batch submission carries a nontrivial cost \cite{BatchBatchBatch}, hence the tendency is to do the exact opposite.
% TODO: explain shader domains
\end{enumerate}

Recently a technique known as \emph{deferred shading} has been gaining popularity, as it offers an elegant solution to both of these problems. Originally proposed in \citet{DeeringDeferred}, the algorithm separates the rendering pipeline into two stages:

\begin{enumerate}
\item Render surface attributes of the visible scene into a set of framebuffers.
\item For each light, evaluate its contribution on the surfaces encoded within a subset of the buffers.
\end{enumerate}

TODO

Decouples light / reflectance shaders from material shaders. Neat, but limited BRDFs, problems with transparency.

% http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter09.html

\section{Graph-based systems}

TODO: Graph-based nice for artists, short turn-around time. Need to communicate well and not have artists go too wild [ref Christer]. Projects succesfully shipped with this approach, more being created, but must still have a way to go down into code and do stuff intuitively, otherwise it's just moving the programming into retarded graphs.

\subsection{Frostbite}

Uses surface shaders, not much info about the other kinds which Renderman provides. Not going away for Frostbite2, a few titles shipped, so probably works out just fine.

\subsection{Mental Mill}

Seems nice on paper, however custom access to lights from MetaSL looks problematic from the point of view of automatically adapting its shaders to various algorithms.

\subsection{McGuire's Abstract shade trees}

An approach for hiding the complexity of creating shaders in graph-based systems. Hides all manual connections though, not obvious what to do when the automatic approach fails.

Mention the stuff it was meant to solve: Whitted's concern for type mismatches.

\section{Permutation management}

Unity3D and Frostbite - Statically generate lots of shaders.

Tri-Ace - Storing of shader permutations generated via play-testing instead of static generation of many combinations.
